<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>On the applicability of the Hadamard as an input modulator for problems of classification.: lg/src/deep_learning/CUDA_backend.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="cyz.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">On the applicability of the Hadamard as an input modulator for problems of classification.
   &#160;<span id="projectnumber">v2.2</span>
   </div>
   <div id="projectbrief">Documentation for lg.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('_c_u_d_a__backend_8hpp_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">CUDA_backend.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="_c_u_d_a__backend_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">// Original Source Code by Meroni (https://www.github.com/Flowx08/).</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">// Modified by Curt√≥ &amp; Zarza.</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">// c@decurto.tw z@dezarza.tw</span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160; </div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#ifndef CUDA_BACKEND_H</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#define CUDA_BACKEND_H</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160; </div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacelg.html">lg</a></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;{</div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160; </div>
<div class="line"><a name="l00017"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html">   17</a></span>&#160;    <span class="keyword">namespace </span>cudnn</div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;    {</div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;        <span class="keywordtype">int</span> <a class="code" href="namespacelg_1_1cudnn.html#a2ca6eb7e6ef6c6530cf8ccd16d4bc780">init</a>();</div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cudnn.html#ac2bdb31de41b622ffdcf8b658ee11de9">destroy</a>();</div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160; </div>
<div class="line"><a name="l00022"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28">   22</a></span>&#160;        <span class="keyword">enum</span> <a class="code" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28">DataType</a></div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;        {</div>
<div class="line"><a name="l00024"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a83f372d1c9db6c53dbadda1e87205c5f">   24</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a83f372d1c9db6c53dbadda1e87205c5f">DATA_FLOAT</a>,</div>
<div class="line"><a name="l00025"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a289847449636c34afd4bc2eabada888e">   25</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a289847449636c34afd4bc2eabada888e">DATA_DOUBLE</a>,</div>
<div class="line"><a name="l00026"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a0507d470b34f8e8ead8992cdae434a12">   26</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a0507d470b34f8e8ead8992cdae434a12">DATA_HALF</a>,</div>
<div class="line"><a name="l00027"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a5a0eb578da57eb366e52c6a237f66779">   27</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a5a0eb578da57eb366e52c6a237f66779">DATA_INT8</a>,</div>
<div class="line"><a name="l00028"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28ad269c23225751f5a6bc371f8ed8ceabd">   28</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28ad269c23225751f5a6bc371f8ed8ceabd">DATA_INT32</a>,</div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;        };</div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160; </div>
<div class="line"><a name="l00031"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48f">   31</a></span>&#160;        <span class="keyword">enum</span> <a class="code" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48f">ActivationType</a></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;        {</div>
<div class="line"><a name="l00033"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fad922f4546f4f7ac7e14a2885e756c219">   33</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fad922f4546f4f7ac7e14a2885e756c219">ACTIVATION_SIGMOID</a>,</div>
<div class="line"><a name="l00034"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fa49219e1ec5035b65f661fc89c955008c">   34</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fa49219e1ec5035b65f661fc89c955008c">ACTIVATION_RELU</a>,</div>
<div class="line"><a name="l00035"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fa0796c0b72c2fab816990630b91b23d03">   35</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fa0796c0b72c2fab816990630b91b23d03">ACTIVATION_TANH</a>,</div>
<div class="line"><a name="l00036"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fa5a518d7d7ee3dc7cd313ff5a209d08f3">   36</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fa5a518d7d7ee3dc7cd313ff5a209d08f3">ACTIVATION_CLIPPED_RELU</a>,</div>
<div class="line"><a name="l00037"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fac36699686abed0eb26a6fe942aed94aa">   37</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fac36699686abed0eb26a6fe942aed94aa">ACTIVATION_ELU</a>,</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;        };</div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160; </div>
<div class="line"><a name="l00040"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6">   40</a></span>&#160;        <span class="keyword">enum</span> <a class="code" href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6">PoolingType</a></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;        {</div>
<div class="line"><a name="l00042"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6a59513495a6fbd432089720a7908c910e">   42</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6a59513495a6fbd432089720a7908c910e">POOLING_MAX</a>,</div>
<div class="line"><a name="l00043"></a><span class="lineno"><a class="line" href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6a169c1eb25fae69de26bcf3342dd116f5">   43</a></span>&#160;            <a class="code" href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6a169c1eb25fae69de26bcf3342dd116f5">POOLING_AVERAGE</a>,</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;        };</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160; </div>
<div class="line"><a name="l00046"></a><span class="lineno"><a class="line" href="classlg_1_1cudnn_1_1_tensor_description.html">   46</a></span>&#160;        <span class="keyword">class </span><a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html">TensorDescription</a></div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;        {</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;            <span class="keyword">public</span>:</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html#a504790fd62796fae5465d432194bdb0a">TensorDescription</a>();</div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html#a504790fd62796fae5465d432194bdb0a">TensorDescription</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> width, <span class="keyword">const</span> <span class="keywordtype">int</span> height, <span class="keyword">const</span> <span class="keywordtype">int</span> depth,</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">int</span> batch_size, <span class="keyword">const</span> <a class="code" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28">DataType</a> type);</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html#a2abad65bccd9638b7ff1615384c93c87">~TensorDescription</a>();</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html#a704f22906a8b907d63f4718e3e3f1658">create</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> width, <span class="keyword">const</span> <span class="keywordtype">int</span> height, <span class="keyword">const</span> <span class="keywordtype">int</span> depth,</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">int</span> batch_size, <span class="keyword">const</span> <a class="code" href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28">DataType</a> type);</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;                <span class="keywordtype">void</span>* <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html#a3c28b8823548b85e3561b0259e923b1a">get</a>();</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160; </div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;            <span class="keyword">private</span>:</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;                <span class="keywordtype">void</span> clear();</div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;                <span class="keywordtype">void</span>* _tensor_description;</div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;        };</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160; </div>
<div class="line"><a name="l00062"></a><span class="lineno"><a class="line" href="classlg_1_1cudnn_1_1_activation.html">   62</a></span>&#160;        <span class="keyword">class </span><a class="code" href="classlg_1_1cudnn_1_1_activation.html">Activation</a></div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;        {</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;            <span class="keyword">public</span>:</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_activation.html#a9b1cb55fd34f68c9572f6e84f2647a86">Activation</a>();</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_activation.html#a9b1cb55fd34f68c9572f6e84f2647a86">Activation</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> size, <span class="keyword">const</span> <span class="keywordtype">int</span> batch_size, <span class="keyword">const</span> <a class="code" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48f">ActivationType</a> type);</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_activation.html#aabd2da347135cfae195fe814648f6b4b">~Activation</a>();</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_activation.html#a0b206097ec8fb0493ca77ed87adcd740">create</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> size, <span class="keyword">const</span> <span class="keywordtype">int</span> batch_size, <span class="keyword">const</span> <a class="code" href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48f">ActivationType</a> type);</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_activation.html#aaa040339c80825cce7b1775010496407">forward</a>(<span class="keywordtype">void</span>* input, <span class="keywordtype">void</span>* output); </div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_activation.html#ab62b12db7c2c367c88fc550cb149696c">backward</a>(<span class="keywordtype">void</span>* input, <span class="keywordtype">void</span>* output, <span class="keywordtype">void</span>* errors, <span class="keywordtype">void</span>* output_errors); </div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160; </div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;            <span class="keyword">private</span>:</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;                <span class="keywordtype">void</span> clear();</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html">TensorDescription</a> _size_description;</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;                <span class="keywordtype">void</span>* _activation_description;</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;        };</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160; </div>
<div class="line"><a name="l00078"></a><span class="lineno"><a class="line" href="classlg_1_1cudnn_1_1_convolution.html">   78</a></span>&#160;        <span class="keyword">class </span><a class="code" href="classlg_1_1cudnn_1_1_convolution.html">Convolution</a></div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;        {</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;            <span class="keyword">public</span>:</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_convolution.html#a0611a6abf187ead5b6c38cfede9059ed">Convolution</a>();</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_convolution.html#a0611a6abf187ead5b6c38cfede9059ed">Convolution</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> input_width, <span class="keyword">const</span> <span class="keywordtype">int</span> input_height, <span class="keyword">const</span> <span class="keywordtype">int</span> input_depth,</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">int</span> batch_size, <span class="keyword">const</span> <span class="keywordtype">int</span> filter_width, <span class="keyword">const</span> <span class="keywordtype">int</span> filter_height, </div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">int</span> filter_count, <span class="keyword">const</span> <span class="keywordtype">int</span> padding_w, <span class="keyword">const</span> <span class="keywordtype">int</span> padding_h,</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">int</span> stride_u, <span class="keyword">const</span> <span class="keywordtype">int</span> stride_v, <span class="keyword">const</span> <span class="keywordtype">bool</span> backward_errors);</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_convolution.html#aa0224d51c8124d8d7c30e39fdcd2c35f">~Convolution</a>();</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_convolution.html#a4ab49c60c2dee793a5b90523244c500f">create</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> input_width, <span class="keyword">const</span> <span class="keywordtype">int</span> input_height, <span class="keyword">const</span> <span class="keywordtype">int</span> input_depth,</div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">int</span> batch_size, <span class="keyword">const</span> <span class="keywordtype">int</span> filter_width, <span class="keyword">const</span> <span class="keywordtype">int</span> filter_height, </div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">int</span> filter_count, <span class="keyword">const</span> <span class="keywordtype">int</span> padding_w, <span class="keyword">const</span> <span class="keywordtype">int</span> padding_h,</div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">int</span> stride_u, <span class="keyword">const</span> <span class="keywordtype">int</span> stride_v, <span class="keyword">const</span> <span class="keywordtype">bool</span> backward_errors);</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_convolution.html#a3ea25c32ef0ea5ae6e221f5ef490f293">forward</a>(<span class="keywordtype">void</span>* input, <span class="keywordtype">void</span>* output, <span class="keywordtype">void</span>* weights, <span class="keywordtype">void</span>* bias, <span class="keywordtype">void</span>* workspace); </div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_convolution.html#a4b00db764114c64c6d2ddef7cfde6656">backward</a>(<span class="keywordtype">void</span>* errors, <span class="keywordtype">void</span>* output_errors, <span class="keywordtype">void</span>* weights, <span class="keywordtype">void</span>* workspace);</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_convolution.html#ad4f81402d0770c413f0d79027bf39644">accumulate_deltas</a>(<span class="keywordtype">void</span>* input, <span class="keywordtype">void</span>* output, <span class="keywordtype">void</span>* errors,</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;                        <span class="keywordtype">void</span>* filter_deltas, <span class="keywordtype">void</span>* bias_deltas, <span class="keywordtype">void</span>* workspace);</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_convolution.html#ae33a537b7b7d30dec571287161487319">update_weights</a>(<span class="keywordtype">void</span>* weights, <span class="keywordtype">void</span>* filter_deltas, <span class="keywordtype">void</span>* bias, <span class="keywordtype">void</span>* bias_deltas, <span class="keyword">const</span> <span class="keywordtype">float</span> learningrate);</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_convolution.html#a9ed1ccaebfd9431a459187c2964e805b">getOutputSize</a>(<span class="keywordtype">int</span>* output_width, <span class="keywordtype">int</span>* output_height, <span class="keywordtype">int</span>* output_depth);</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;                <span class="keywordtype">int</span> <a class="code" href="classlg_1_1cudnn_1_1_convolution.html#a4ff6bc869cfb20fcd30321e346a46466">getWorkspaceSize</a>();</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160; </div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;            <span class="keyword">private</span>:</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;                <span class="keywordtype">void</span> clear();</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html">TensorDescription</a> _input_description;</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html">TensorDescription</a> _output_description;</div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html">TensorDescription</a> _bias_description;</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;                <span class="keywordtype">int</span> _workspace_size;</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;                <span class="keywordtype">int</span> _weights_size;</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;                <span class="keywordtype">int</span> _bias_size;</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;                <span class="keywordtype">int</span> _output_width, _output_height, _output_depth;</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;                <span class="keywordtype">void</span>* _filter_description;</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;                <span class="keywordtype">void</span>* _convolution_description;</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;                <span class="keywordtype">void</span>* _fwd_algorithm_description;</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;                <span class="keywordtype">void</span>* _bwd_filter_algorithm_description;</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;                <span class="keywordtype">void</span>* _bwd_data_algorithm_description;</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;        };</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160; </div>
<div class="line"><a name="l00115"></a><span class="lineno"><a class="line" href="classlg_1_1cudnn_1_1_pooling.html">  115</a></span>&#160;        <span class="keyword">class </span><a class="code" href="classlg_1_1cudnn_1_1_pooling.html">Pooling</a></div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;        {</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;            <span class="keyword">public</span>:</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_pooling.html#a7ecd9addedd5778e0ecca3dedf7aa15c">Pooling</a>();</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_pooling.html#a7ecd9addedd5778e0ecca3dedf7aa15c">Pooling</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> input_width, <span class="keyword">const</span> <span class="keywordtype">int</span> input_height, <span class="keyword">const</span> <span class="keywordtype">int</span> input_count, <span class="keyword">const</span> <span class="keywordtype">int</span> batch_size,</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">int</span> pooling_width, <span class="keyword">const</span> <span class="keywordtype">int</span> pooling_height, <span class="keyword">const</span> <a class="code" href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6">PoolingType</a> type);</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_pooling.html#a0130c13ac069fa611bf23cbf258871c1">~Pooling</a>();</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_pooling.html#a25c3722354d56b01a5f78435ff2e6bac">clear</a>();</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_pooling.html#a08072ec59a01232cef7531876f729f73">create</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> input_width, <span class="keyword">const</span> <span class="keywordtype">int</span> input_height, <span class="keyword">const</span> <span class="keywordtype">int</span> input_count, <span class="keyword">const</span> <span class="keywordtype">int</span> batch_size,</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">int</span> pooling_width, <span class="keyword">const</span> <span class="keywordtype">int</span> pooling_height, <span class="keyword">const</span> <a class="code" href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6">PoolingType</a> type);</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_pooling.html#a27be7fe5650f8c41c28921970d2b9ffe">forward</a>(<span class="keywordtype">void</span>* input, <span class="keywordtype">void</span>* output);</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_pooling.html#abf652f83a4e4e570ee6e43b0913ca759">backward</a>(<span class="keywordtype">void</span>* input, <span class="keywordtype">void</span>* outputs, <span class="keywordtype">void</span>* errors, <span class="keywordtype">void</span>* out_errors);</div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160; </div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;            <span class="keyword">private</span>:</div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;                <span class="keywordtype">void</span>* _pooling_description;</div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html">TensorDescription</a> _input_description;</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html">TensorDescription</a> _output_description;</div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;        };</div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160; </div>
<div class="line"><a name="l00134"></a><span class="lineno"><a class="line" href="classlg_1_1cudnn_1_1_dropout.html">  134</a></span>&#160;        <span class="keyword">class </span><a class="code" href="classlg_1_1cudnn_1_1_dropout.html">Dropout</a></div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;        {</div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;            <span class="keyword">public</span>:</div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_dropout.html#a1fac1fb41698b15d207dc956965a7dfe">Dropout</a>();</div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_dropout.html#a1fac1fb41698b15d207dc956965a7dfe">Dropout</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> input_size, <span class="keyword">const</span> <span class="keywordtype">float</span> dropout_probability, <span class="keywordtype">void</span>* state_buffer);</div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_dropout.html#a42ee5e103620977da2950ada0ff1e2b6">~Dropout</a>();</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_dropout.html#aeb340888ab83d9ea0ccbb4ab2d714b12">clear</a>();</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_dropout.html#a27ce1a6ddce88949121934f3599b3552">create</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> input_size, <span class="keyword">const</span> <span class="keywordtype">float</span> dropout_probability, <span class="keywordtype">void</span>* state_buffer);</div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_dropout.html#af45ddcc72851f4889d4bd361d82df748">forward</a>(<span class="keywordtype">void</span>* input, <span class="keywordtype">void</span>* output, <span class="keywordtype">void</span>* reserve_space_buffer);</div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;                <span class="keywordtype">void</span> <a class="code" href="classlg_1_1cudnn_1_1_dropout.html#a760c340d9758c309f9ce0d0a2dfabf71">backward</a>(<span class="keywordtype">void</span>* errors, <span class="keywordtype">void</span>* out_errors, <span class="keywordtype">void</span>* reserve_space_buffer);</div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;                <span class="keywordtype">size_t</span> <a class="code" href="classlg_1_1cudnn_1_1_dropout.html#afc2d554001e68428ef991bca4bdbfa53">getStatesSize</a>();</div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;                <span class="keywordtype">size_t</span> <a class="code" href="classlg_1_1cudnn_1_1_dropout.html#ae8da161cb40aed9d4ba0509cfaed1352">getReserveSpaceSize</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> input_size);</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160; </div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;            <span class="keyword">private</span>:</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;                <span class="keywordtype">void</span>* _dropout_description;</div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;                <span class="keywordtype">size_t</span> _states_size;</div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;                <span class="keywordtype">size_t</span> _reserve_space_size;</div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;                <a class="code" href="classlg_1_1cudnn_1_1_tensor_description.html">TensorDescription</a> _input_description;</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;        };</div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160; </div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;    } <span class="comment">/* namespace cudnn */</span></div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160; </div>
<div class="line"><a name="l00159"></a><span class="lineno"><a class="line" href="namespacelg_1_1cuda.html">  159</a></span>&#160;    <span class="keyword">namespace </span>cuda</div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;    {</div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a8911de947294cbb37113ce9e8d550783">convn_forward</a>(<span class="keywordtype">float</span>* weights, <span class="keywordtype">float</span>* bias, <span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs,</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;                <span class="keywordtype">int</span>* out_in_map, <span class="keywordtype">int</span> input_width, <span class="keywordtype">int</span> input_height, <span class="keywordtype">int</span> input_count, <span class="keywordtype">int</span> stride,</div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;                <span class="keywordtype">int</span> output_width, <span class="keywordtype">int</span> output_height, <span class="keywordtype">int</span> filters_count, <span class="keywordtype">int</span> filter_area);</div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#aa4ef754e9424188009a71c1a363aa94d">convn_backward</a>(<span class="keywordtype">float</span>* weights, <span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* errors,</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;                <span class="keywordtype">int</span>* in_weight_map, <span class="keywordtype">int</span>* in_out_map, <span class="keywordtype">int</span> input_count, <span class="keywordtype">int</span> output_size, <span class="keywordtype">int</span> input_width,</div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;                <span class="keywordtype">int</span> input_height, <span class="keywordtype">int</span> filter_area, <span class="keywordtype">int</span> filters_count);</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a2fa8129596126da6ab6fd12b7570e256">convn_accumulate_deltas</a>(<span class="keywordtype">float</span>* weights_deltas, <span class="keywordtype">float</span>* bias_deltas, <span class="keywordtype">float</span>* errors, <span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs,</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;                <span class="keywordtype">int</span>* out_in_map, <span class="keywordtype">int</span> input_count, <span class="keywordtype">int</span> input_width, <span class="keywordtype">int</span> input_height, <span class="keywordtype">int</span> output_size,</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;                <span class="keywordtype">int</span> filter_area, <span class="keywordtype">int</span> filters_count);</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#aabc1ca86849f1b325416d5fc042d4cee">convn_update_parameters</a>(<span class="keywordtype">float</span>* weights, <span class="keywordtype">float</span>* bias, <span class="keywordtype">float</span>* weights_deltas, <span class="keywordtype">float</span>* bias_deltas, <span class="keywordtype">int</span> filter_area, </div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;                <span class="keywordtype">int</span> input_count, <span class="keywordtype">int</span> filter_count, <span class="keywordtype">float</span> learningrate);</div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a9faebc3673f09ecfc225c21738da5af3">maxpooling_forward</a>(<span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span>* maxbuffer, <span class="keywordtype">int</span> input_width, <span class="keywordtype">int</span> input_height,</div>
<div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;                <span class="keywordtype">int</span> input_count, <span class="keywordtype">int</span> stride, <span class="keywordtype">int</span> filter_size, <span class="keywordtype">int</span> output_width, <span class="keywordtype">int</span> output_height);</div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#ab502580e89328622329728926b168ced">maxpooling_backward</a>(<span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* errors, <span class="keywordtype">int</span>* maxbuffer, <span class="keywordtype">int</span> input_width, <span class="keywordtype">int</span> input_height,</div>
<div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;                <span class="keywordtype">int</span> input_count, <span class="keywordtype">int</span> stride, <span class="keywordtype">int</span> filter_size, <span class="keywordtype">int</span> output_width, <span class="keywordtype">int</span> output_height);</div>
<div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a6859dafb7adc62c944d3049197cc3aa4">averagepooling_forward</a>(<span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> input_width, <span class="keywordtype">int</span> input_height,</div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;                <span class="keywordtype">int</span> input_count, <span class="keywordtype">int</span> stride, <span class="keywordtype">int</span> filter_size, <span class="keywordtype">int</span> output_width, <span class="keywordtype">int</span> output_height);</div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a3a18f9046738e9209bbc4bdd101c2915">averagepooling_backward</a>(<span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* errors, <span class="keywordtype">int</span> input_width, <span class="keywordtype">int</span> input_height,</div>
<div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;                <span class="keywordtype">int</span> input_count, <span class="keywordtype">int</span> stride, <span class="keywordtype">int</span> filter_size, <span class="keywordtype">int</span> output_width, <span class="keywordtype">int</span> output_height);</div>
<div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a17f5d386c6a971e477fefb1c443fb408">linear_forward</a>(<span class="keywordtype">float</span>* weights, <span class="keywordtype">float</span>* bias, <span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> input_size, <span class="keywordtype">int</span> output_size, <span class="keywordtype">bool</span> use_bias, <span class="keywordtype">bool</span> accumulate);</div>
<div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a23d87aeb9500b8ef1476535a39baa3d3">linear_backward</a>(<span class="keywordtype">float</span>* weights, <span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* errors, <span class="keywordtype">int</span> input_size, <span class="keywordtype">int</span> output_size);</div>
<div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#af1943bb4b10ca0f9465ed36b5063e534">linear_accumulate_deltas</a>(<span class="keywordtype">float</span>* deltas, <span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* errors, <span class="keywordtype">int</span> input_size, <span class="keywordtype">int</span> output_size, <span class="keywordtype">bool</span> use_bias);</div>
<div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a6e6de7213575b5eecba3d7da46dd11db">linear_update_parameters</a>(<span class="keywordtype">float</span>* weights, <span class="keywordtype">float</span>* bias, <span class="keywordtype">float</span>* deltas, <span class="keywordtype">float</span> learningrate, <span class="keywordtype">int</span> input_size, <span class="keywordtype">int</span> output_size);</div>
<div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#afbcb57abfd9468a3107a5fb8876e3d22">sigmoid_forward</a>(<span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#ab87ff03b7876a608d263ed2103a0399e">sigmoid_backward</a>(<span class="keywordtype">float</span>* errors, <span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#ae6adb1a572de78eae4715c1c8137c026">relu_forward</a>(<span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#ab0642d5b6d1a28b52236ab85f3a53925">relu_backward</a>(<span class="keywordtype">float</span>* errors, <span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a0fead1b0d84ba90d494c808c9b4c33fe">tanh_forward</a>(<span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a3e0acb2ce86052848da5bbcc6629d56d">tanh_backward</a>(<span class="keywordtype">float</span>* errors, <span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a8c62455098b6a8ab29a6113e840175a8">dropout_forward</a>(<span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> seed, <span class="keywordtype">float</span> dropout_probability, <span class="keywordtype">bool</span> training, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a9d9e3a4cf4915ca097f8c8edcbfc0e26">dropout_backward</a>(<span class="keywordtype">float</span>* errors, <span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">float</span> dropout_probability, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a2924760c84069a2841f300848c0d7b85">selu_forward</a>(<span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#ae0db6f2ac2908e7161386f0a36df4560">selu_backward</a>(<span class="keywordtype">float</span>* errors, <span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a85299cc9e76e9ff15803eb9101e78460">normalization_forward</a>(<span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* deviation, <span class="keywordtype">float</span>* normalized,</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;                <span class="keywordtype">float</span>* outputs, <span class="keywordtype">float</span>* variance, <span class="keywordtype">float</span>* gamma, <span class="keywordtype">float</span>* beta, <span class="keywordtype">float</span> epsilon, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a25134b03f29a49340cfca6acb6ff519c">normalization_backward</a>(<span class="keywordtype">float</span>* errors, <span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* deviation,</div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;                <span class="keywordtype">float</span>* variance, <span class="keywordtype">float</span>* gamma, <span class="keywordtype">float</span>* beta, <span class="keywordtype">float</span> epsilon, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a0e4f26dc450867d2347a2d72ed383733">normalization_accumulate_deltas</a>(<span class="keywordtype">float</span>* errors, <span class="keywordtype">float</span>* deviation, <span class="keywordtype">float</span>* variance, <span class="keywordtype">float</span>* d_gamma, <span class="keywordtype">float</span>* d_beta, <span class="keywordtype">float</span> epsilon, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a965f4592cfb4e6b9f7f1abfa3a1005d8">normalization_update_parameters</a>(<span class="keywordtype">float</span>* gamma, <span class="keywordtype">float</span>* beta, <span class="keywordtype">float</span>* d_gamma, <span class="keywordtype">float</span>* d_beta, <span class="keywordtype">float</span> momentum, <span class="keywordtype">int</span> size, <span class="keywordtype">float</span> learningrate);</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a4b1138745ab9fde9daac0c42cb68f66f">sparse_indices</a>(<span class="keywordtype">float</span>* inputs, <span class="keywordtype">int</span> inputs_size, <span class="keywordtype">int</span>* indices, <span class="keywordtype">int</span>* tmp_indices, <span class="keywordtype">int</span>* indices_count);</div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a5b2010c67b263a2325c0f66a5e5043be">linear_sparse_forward</a>(<span class="keywordtype">float</span>* weights, <span class="keywordtype">float</span>* bias, <span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span>* indices, <span class="keywordtype">int</span>* indices_count, <span class="keywordtype">int</span> input_size, <span class="keywordtype">int</span> output_size);</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#abd2ace1b9d637e47db6c5a643b73cd71">linear_sparse_accumulate_deltas</a>(<span class="keywordtype">float</span>* deltas, <span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* errors, <span class="keywordtype">int</span>* indices, <span class="keywordtype">int</span>* indices_count, <span class="keywordtype">int</span> input_size, <span class="keywordtype">int</span> output_size);</div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a52532045d8ca46b5e0fa99a6810362a6">concatenate_forward</a>(<span class="keywordtype">float</span>** inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span>* sizes, <span class="keywordtype">int</span> input_count, <span class="keywordtype">int</span> total_size);</div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a3f1b29f5fcbbd0e7577c4b0060ffbaaa">concatenate_backward</a>(<span class="keywordtype">float</span>* errors, <span class="keywordtype">float</span>** out_errors, <span class="keywordtype">int</span>* sizes, <span class="keywordtype">int</span> input_count, <span class="keywordtype">int</span> total_size);</div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#af6f534536e457051e65effdbc7534a6d">softmax_forward</a>(<span class="keywordtype">float</span>* inputs, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">float</span> scale, <span class="keywordtype">int</span> size, <span class="keywordtype">float</span> epsilon);</div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#ae6100dbc18d64618537e768e67a5eae4">softmax_backward</a>(<span class="keywordtype">float</span>* errors, <span class="keywordtype">float</span>* out_errors, <span class="keywordtype">float</span>* outputs, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a4f1ff47b761603f6600eab5dcdfb0f43">cost_crossentropy</a>(<span class="keywordtype">float</span>* prediction, <span class="keywordtype">float</span>* target, <span class="keywordtype">float</span>* errors, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160; </div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a06d4a9fec2e50a26d69a90897dbd7d84">gradient_clipping</a>(<span class="keywordtype">float</span>* deltas, <span class="keywordtype">int</span> size, <span class="keyword">const</span> <span class="keywordtype">float</span> clipping_deviation);</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a1e622d4a2dbd418b7a4da5839beabe8f">l1_regularization</a>(<span class="keywordtype">float</span>* weights, <span class="keyword">const</span> <span class="keywordtype">float</span> l1_factor, <span class="keyword">const</span> <span class="keywordtype">float</span> learningrate, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a1f640f43ce4d3a9f5017b85d68369b7e">l2_regularization</a>(<span class="keywordtype">float</span>* weights, <span class="keyword">const</span> <span class="keywordtype">float</span> l2_factor, <span class="keyword">const</span> <span class="keywordtype">float</span> learningrate, <span class="keywordtype">int</span> size);</div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160; </div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;        <span class="comment">//Image data augmentation</span></div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a159d5855d0b6c8263d0b734b8c718440">image_translate</a>(<span class="keywordtype">float</span>* image, <span class="keywordtype">float</span>* result_buffer, <span class="keyword">const</span> <span class="keywordtype">int</span> width, <span class="keyword">const</span> <span class="keywordtype">int</span> height, <span class="keyword">const</span> <span class="keywordtype">int</span> channels, <span class="keyword">const</span> <span class="keywordtype">int</span> by_x, <span class="keyword">const</span> <span class="keywordtype">int</span> by_y);</div>
<div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a75256a409482891fa3c8852714ef3b93">image_vertical_flip</a>(<span class="keywordtype">float</span>* image, <span class="keyword">const</span> <span class="keywordtype">int</span> width, <span class="keyword">const</span> <span class="keywordtype">int</span> height, <span class="keyword">const</span> <span class="keywordtype">int</span> channels);</div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a87ec4c9b53aef96dbfefda3df54dfa2d">image_horizontal_flip</a>(<span class="keywordtype">float</span>* image, <span class="keyword">const</span> <span class="keywordtype">int</span> width, <span class="keyword">const</span> <span class="keywordtype">int</span> height, <span class="keyword">const</span> <span class="keywordtype">int</span> channels);</div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#af15bc16b0cb62a92e8d0f6bf966f0e0c">image_rotate</a>(<span class="keywordtype">float</span>* image, <span class="keywordtype">float</span>* result_buffer, <span class="keyword">const</span> <span class="keywordtype">int</span> width, <span class="keyword">const</span> <span class="keywordtype">int</span> height, <span class="keyword">const</span> <span class="keywordtype">int</span> channels, <span class="keyword">const</span> <span class="keywordtype">float</span> degrees);</div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a2dfc5b5558f9fc2dd45adae28f200594">image_scale</a>(<span class="keywordtype">float</span>* image, <span class="keywordtype">float</span>* result_buffer, <span class="keyword">const</span> <span class="keywordtype">int</span> width, <span class="keyword">const</span> <span class="keywordtype">int</span> height, <span class="keyword">const</span> <span class="keywordtype">int</span> channels, <span class="keyword">const</span> <span class="keywordtype">float</span> scale_factor);</div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;        <span class="keywordtype">void</span> <a class="code" href="namespacelg_1_1cuda.html#a6155fb898132cd2eea9ab0bebf05da91">image_add_noise</a>(<span class="keywordtype">float</span>* image, <span class="keyword">const</span> <span class="keywordtype">int</span> width, <span class="keyword">const</span> <span class="keywordtype">int</span> height, <span class="keyword">const</span> <span class="keywordtype">int</span> channels, <span class="keyword">const</span> <span class="keywordtype">float</span> noise_probability);</div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160; </div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;    } <span class="comment">/* namespace cuda */</span></div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160; </div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;} <span class="comment">/* namespace lg */</span></div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160; </div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;<span class="preprocessor">#endif </span><span class="comment">/* end of include guard: CUDA_BACKEND_H */</span><span class="preprocessor"></span></div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160; </div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<div class="ttc" id="anamespacelg_1_1cudnn_html_ae723bd7649b468936d3f5ffb1163dd28"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28">lg::cudnn::DataType</a></div><div class="ttdeci">DataType</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00022">CUDA_backend.hpp:22</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a3f1b29f5fcbbd0e7577c4b0060ffbaaa"><div class="ttname"><a href="namespacelg_1_1cuda.html#a3f1b29f5fcbbd0e7577c4b0060ffbaaa">lg::cuda::concatenate_backward</a></div><div class="ttdeci">void concatenate_backward(float *errors, float **out_errors, int *sizes, int input_count, int total_size)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a1e622d4a2dbd418b7a4da5839beabe8f"><div class="ttname"><a href="namespacelg_1_1cuda.html#a1e622d4a2dbd418b7a4da5839beabe8f">lg::cuda::l1_regularization</a></div><div class="ttdeci">void l1_regularization(float *weights, const float l1_factor, const float learningrate, int size)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00499">CPU_backend.cpp:499</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_tensor_description_html_a2abad65bccd9638b7ff1615384c93c87"><div class="ttname"><a href="classlg_1_1cudnn_1_1_tensor_description.html#a2abad65bccd9638b7ff1615384c93c87">lg::cudnn::TensorDescription::~TensorDescription</a></div><div class="ttdeci">~TensorDescription()</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_convolution_html_a4ab49c60c2dee793a5b90523244c500f"><div class="ttname"><a href="classlg_1_1cudnn_1_1_convolution.html#a4ab49c60c2dee793a5b90523244c500f">lg::cudnn::Convolution::create</a></div><div class="ttdeci">void create(const int input_width, const int input_height, const int input_depth, const int batch_size, const int filter_width, const int filter_height, const int filter_count, const int padding_w, const int padding_h, const int stride_u, const int stride_v, const bool backward_errors)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_convolution_html_a0611a6abf187ead5b6c38cfede9059ed"><div class="ttname"><a href="classlg_1_1cudnn_1_1_convolution.html#a0611a6abf187ead5b6c38cfede9059ed">lg::cudnn::Convolution::Convolution</a></div><div class="ttdeci">Convolution()</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_tensor_description_html_a704f22906a8b907d63f4718e3e3f1658"><div class="ttname"><a href="classlg_1_1cudnn_1_1_tensor_description.html#a704f22906a8b907d63f4718e3e3f1658">lg::cudnn::TensorDescription::create</a></div><div class="ttdeci">void create(const int width, const int height, const int depth, const int batch_size, const DataType type)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_activation_html_a0b206097ec8fb0493ca77ed87adcd740"><div class="ttname"><a href="classlg_1_1cudnn_1_1_activation.html#a0b206097ec8fb0493ca77ed87adcd740">lg::cudnn::Activation::create</a></div><div class="ttdeci">void create(const int size, const int batch_size, const ActivationType type)</div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ac49356b14c89bae0ff4d4c422719c48f"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48f">lg::cudnn::ActivationType</a></div><div class="ttdeci">ActivationType</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00031">CUDA_backend.hpp:31</a></div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ae723bd7649b468936d3f5ffb1163dd28a83f372d1c9db6c53dbadda1e87205c5f"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a83f372d1c9db6c53dbadda1e87205c5f">lg::cudnn::DATA_FLOAT</a></div><div class="ttdeci">@ DATA_FLOAT</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00024">CUDA_backend.hpp:24</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_convolution_html_ae33a537b7b7d30dec571287161487319"><div class="ttname"><a href="classlg_1_1cudnn_1_1_convolution.html#ae33a537b7b7d30dec571287161487319">lg::cudnn::Convolution::update_weights</a></div><div class="ttdeci">void update_weights(void *weights, void *filter_deltas, void *bias, void *bias_deltas, const float learningrate)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_af1943bb4b10ca0f9465ed36b5063e534"><div class="ttname"><a href="namespacelg_1_1cuda.html#af1943bb4b10ca0f9465ed36b5063e534">lg::cuda::linear_accumulate_deltas</a></div><div class="ttdeci">void linear_accumulate_deltas(float *deltas, float *inputs, float *errors, int input_size, int output_size, bool use_bias)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00113">CPU_backend.cpp:113</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a23d87aeb9500b8ef1476535a39baa3d3"><div class="ttname"><a href="namespacelg_1_1cuda.html#a23d87aeb9500b8ef1476535a39baa3d3">lg::cuda::linear_backward</a></div><div class="ttdeci">void linear_backward(float *weights, float *out_errors, float *errors, int input_size, int output_size)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00103">CPU_backend.cpp:103</a></div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ac49356b14c89bae0ff4d4c422719c48fa0796c0b72c2fab816990630b91b23d03"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fa0796c0b72c2fab816990630b91b23d03">lg::cudnn::ACTIVATION_TANH</a></div><div class="ttdeci">@ ACTIVATION_TANH</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00035">CUDA_backend.hpp:35</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_pooling_html_a25c3722354d56b01a5f78435ff2e6bac"><div class="ttname"><a href="classlg_1_1cudnn_1_1_pooling.html#a25c3722354d56b01a5f78435ff2e6bac">lg::cudnn::Pooling::clear</a></div><div class="ttdeci">void clear()</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_dropout_html_a1fac1fb41698b15d207dc956965a7dfe"><div class="ttname"><a href="classlg_1_1cudnn_1_1_dropout.html#a1fac1fb41698b15d207dc956965a7dfe">lg::cudnn::Dropout::Dropout</a></div><div class="ttdeci">Dropout()</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_activation_html_ab62b12db7c2c367c88fc550cb149696c"><div class="ttname"><a href="classlg_1_1cudnn_1_1_activation.html#ab62b12db7c2c367c88fc550cb149696c">lg::cudnn::Activation::backward</a></div><div class="ttdeci">void backward(void *input, void *output, void *errors, void *output_errors)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a9d9e3a4cf4915ca097f8c8edcbfc0e26"><div class="ttname"><a href="namespacelg_1_1cuda.html#a9d9e3a4cf4915ca097f8c8edcbfc0e26">lg::cuda::dropout_backward</a></div><div class="ttdeci">void dropout_backward(float *errors, float *out_errors, float *outputs, float dropout_probability, int size)</div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ae723bd7649b468936d3f5ffb1163dd28a0507d470b34f8e8ead8992cdae434a12"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a0507d470b34f8e8ead8992cdae434a12">lg::cudnn::DATA_HALF</a></div><div class="ttdeci">@ DATA_HALF</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00026">CUDA_backend.hpp:26</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_pooling_html"><div class="ttname"><a href="classlg_1_1cudnn_1_1_pooling.html">lg::cudnn::Pooling</a></div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00115">CUDA_backend.hpp:115</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_convolution_html_a9ed1ccaebfd9431a459187c2964e805b"><div class="ttname"><a href="classlg_1_1cudnn_1_1_convolution.html#a9ed1ccaebfd9431a459187c2964e805b">lg::cudnn::Convolution::getOutputSize</a></div><div class="ttdeci">void getOutputSize(int *output_width, int *output_height, int *output_depth)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a159d5855d0b6c8263d0b734b8c718440"><div class="ttname"><a href="namespacelg_1_1cuda.html#a159d5855d0b6c8263d0b734b8c718440">lg::cuda::image_translate</a></div><div class="ttdeci">void image_translate(float *image, float *result_buffer, const int width, const int height, const int channels, const int by_x, const int by_y)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a75256a409482891fa3c8852714ef3b93"><div class="ttname"><a href="namespacelg_1_1cuda.html#a75256a409482891fa3c8852714ef3b93">lg::cuda::image_vertical_flip</a></div><div class="ttdeci">void image_vertical_flip(float *image, const int width, const int height, const int channels)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_pooling_html_a27be7fe5650f8c41c28921970d2b9ffe"><div class="ttname"><a href="classlg_1_1cudnn_1_1_pooling.html#a27be7fe5650f8c41c28921970d2b9ffe">lg::cudnn::Pooling::forward</a></div><div class="ttdeci">void forward(void *input, void *output)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_tensor_description_html_a504790fd62796fae5465d432194bdb0a"><div class="ttname"><a href="classlg_1_1cudnn_1_1_tensor_description.html#a504790fd62796fae5465d432194bdb0a">lg::cudnn::TensorDescription::TensorDescription</a></div><div class="ttdeci">TensorDescription()</div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ae723bd7649b468936d3f5ffb1163dd28a5a0eb578da57eb366e52c6a237f66779"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a5a0eb578da57eb366e52c6a237f66779">lg::cudnn::DATA_INT8</a></div><div class="ttdeci">@ DATA_INT8</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00027">CUDA_backend.hpp:27</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_ab87ff03b7876a608d263ed2103a0399e"><div class="ttname"><a href="namespacelg_1_1cuda.html#ab87ff03b7876a608d263ed2103a0399e">lg::cuda::sigmoid_backward</a></div><div class="ttdeci">void sigmoid_backward(float *errors, float *out_errors, float *outputs, int size)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_activation_html_aaa040339c80825cce7b1775010496407"><div class="ttname"><a href="classlg_1_1cudnn_1_1_activation.html#aaa040339c80825cce7b1775010496407">lg::cudnn::Activation::forward</a></div><div class="ttdeci">void forward(void *input, void *output)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_dropout_html_a760c340d9758c309f9ce0d0a2dfabf71"><div class="ttname"><a href="classlg_1_1cudnn_1_1_dropout.html#a760c340d9758c309f9ce0d0a2dfabf71">lg::cudnn::Dropout::backward</a></div><div class="ttdeci">void backward(void *errors, void *out_errors, void *reserve_space_buffer)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_tensor_description_html"><div class="ttname"><a href="classlg_1_1cudnn_1_1_tensor_description.html">lg::cudnn::TensorDescription</a></div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00046">CUDA_backend.hpp:46</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a25134b03f29a49340cfca6acb6ff519c"><div class="ttname"><a href="namespacelg_1_1cuda.html#a25134b03f29a49340cfca6acb6ff519c">lg::cuda::normalization_backward</a></div><div class="ttdeci">void normalization_backward(float *errors, float *out_errors, float *deviation, float *variance, float *gamma, float *beta, float epsilon, int size)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00189">CPU_backend.cpp:189</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a6859dafb7adc62c944d3049197cc3aa4"><div class="ttname"><a href="namespacelg_1_1cuda.html#a6859dafb7adc62c944d3049197cc3aa4">lg::cuda::averagepooling_forward</a></div><div class="ttdeci">void averagepooling_forward(float *inputs, float *outputs, int input_width, int input_height, int input_count, int stride, int filter_size, int output_width, int output_height)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00318">CPU_backend.cpp:318</a></div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ac2bdb31de41b622ffdcf8b658ee11de9"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ac2bdb31de41b622ffdcf8b658ee11de9">lg::cudnn::destroy</a></div><div class="ttdeci">void destroy()</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_abd2ace1b9d637e47db6c5a643b73cd71"><div class="ttname"><a href="namespacelg_1_1cuda.html#abd2ace1b9d637e47db6c5a643b73cd71">lg::cuda::linear_sparse_accumulate_deltas</a></div><div class="ttdeci">void linear_sparse_accumulate_deltas(float *deltas, float *inputs, float *errors, int *indices, int *indices_count, int input_size, int output_size)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_pooling_html_a0130c13ac069fa611bf23cbf258871c1"><div class="ttname"><a href="classlg_1_1cudnn_1_1_pooling.html#a0130c13ac069fa611bf23cbf258871c1">lg::cudnn::Pooling::~Pooling</a></div><div class="ttdeci">~Pooling()</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a3e0acb2ce86052848da5bbcc6629d56d"><div class="ttname"><a href="namespacelg_1_1cuda.html#a3e0acb2ce86052848da5bbcc6629d56d">lg::cuda::tanh_backward</a></div><div class="ttdeci">void tanh_backward(float *errors, float *out_errors, float *outputs, int size)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a52532045d8ca46b5e0fa99a6810362a6"><div class="ttname"><a href="namespacelg_1_1cuda.html#a52532045d8ca46b5e0fa99a6810362a6">lg::cuda::concatenate_forward</a></div><div class="ttdeci">void concatenate_forward(float **inputs, float *outputs, int *sizes, int input_count, int total_size)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a0fead1b0d84ba90d494c808c9b4c33fe"><div class="ttname"><a href="namespacelg_1_1cuda.html#a0fead1b0d84ba90d494c808c9b4c33fe">lg::cuda::tanh_forward</a></div><div class="ttdeci">void tanh_forward(float *inputs, float *outputs, int size)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_afbcb57abfd9468a3107a5fb8876e3d22"><div class="ttname"><a href="namespacelg_1_1cuda.html#afbcb57abfd9468a3107a5fb8876e3d22">lg::cuda::sigmoid_forward</a></div><div class="ttdeci">void sigmoid_forward(float *inputs, float *outputs, int size)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a1f640f43ce4d3a9f5017b85d68369b7e"><div class="ttname"><a href="namespacelg_1_1cuda.html#a1f640f43ce4d3a9f5017b85d68369b7e">lg::cuda::l2_regularization</a></div><div class="ttdeci">void l2_regularization(float *weights, const float l2_factor, const float learningrate, int size)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00506">CPU_backend.cpp:506</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_af15bc16b0cb62a92e8d0f6bf966f0e0c"><div class="ttname"><a href="namespacelg_1_1cuda.html#af15bc16b0cb62a92e8d0f6bf966f0e0c">lg::cuda::image_rotate</a></div><div class="ttdeci">void image_rotate(float *image, float *result_buffer, const int width, const int height, const int channels, const float degrees)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_convolution_html_a3ea25c32ef0ea5ae6e221f5ef490f293"><div class="ttname"><a href="classlg_1_1cudnn_1_1_convolution.html#a3ea25c32ef0ea5ae6e221f5ef490f293">lg::cudnn::Convolution::forward</a></div><div class="ttdeci">void forward(void *input, void *output, void *weights, void *bias, void *workspace)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_dropout_html_afc2d554001e68428ef991bca4bdbfa53"><div class="ttname"><a href="classlg_1_1cudnn_1_1_dropout.html#afc2d554001e68428ef991bca4bdbfa53">lg::cudnn::Dropout::getStatesSize</a></div><div class="ttdeci">size_t getStatesSize()</div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_a450ec4165ca3788e681e05f42260afc6a169c1eb25fae69de26bcf3342dd116f5"><div class="ttname"><a href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6a169c1eb25fae69de26bcf3342dd116f5">lg::cudnn::POOLING_AVERAGE</a></div><div class="ttdeci">@ POOLING_AVERAGE</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00043">CUDA_backend.hpp:43</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a0e4f26dc450867d2347a2d72ed383733"><div class="ttname"><a href="namespacelg_1_1cuda.html#a0e4f26dc450867d2347a2d72ed383733">lg::cuda::normalization_accumulate_deltas</a></div><div class="ttdeci">void normalization_accumulate_deltas(float *errors, float *deviation, float *variance, float *d_gamma, float *d_beta, float epsilon, int size)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00207">CPU_backend.cpp:207</a></div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ae723bd7649b468936d3f5ffb1163dd28a289847449636c34afd4bc2eabada888e"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28a289847449636c34afd4bc2eabada888e">lg::cudnn::DATA_DOUBLE</a></div><div class="ttdeci">@ DATA_DOUBLE</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00025">CUDA_backend.hpp:25</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a6e6de7213575b5eecba3d7da46dd11db"><div class="ttname"><a href="namespacelg_1_1cuda.html#a6e6de7213575b5eecba3d7da46dd11db">lg::cuda::linear_update_parameters</a></div><div class="ttdeci">void linear_update_parameters(float *weights, float *bias, float *deltas, float learningrate, int input_size, int output_size)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00125">CPU_backend.cpp:125</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_activation_html_a9b1cb55fd34f68c9572f6e84f2647a86"><div class="ttname"><a href="classlg_1_1cudnn_1_1_activation.html#a9b1cb55fd34f68c9572f6e84f2647a86">lg::cudnn::Activation::Activation</a></div><div class="ttdeci">Activation()</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a8911de947294cbb37113ce9e8d550783"><div class="ttname"><a href="namespacelg_1_1cuda.html#a8911de947294cbb37113ce9e8d550783">lg::cuda::convn_forward</a></div><div class="ttdeci">void convn_forward(float *weights, float *bias, float *inputs, float *outputs, int *out_in_map, int input_width, int input_height, int input_count, int stride, int output_width, int output_height, int filters_count, int filter_area)</div><div class="ttdoc">CUDA DEEPLEARNING INTERFACE.</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00027">CPU_backend.cpp:27</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_dropout_html_aeb340888ab83d9ea0ccbb4ab2d714b12"><div class="ttname"><a href="classlg_1_1cudnn_1_1_dropout.html#aeb340888ab83d9ea0ccbb4ab2d714b12">lg::cudnn::Dropout::clear</a></div><div class="ttdeci">void clear()</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_ab0642d5b6d1a28b52236ab85f3a53925"><div class="ttname"><a href="namespacelg_1_1cuda.html#ab0642d5b6d1a28b52236ab85f3a53925">lg::cuda::relu_backward</a></div><div class="ttdeci">void relu_backward(float *errors, float *out_errors, float *outputs, int size)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a5b2010c67b263a2325c0f66a5e5043be"><div class="ttname"><a href="namespacelg_1_1cuda.html#a5b2010c67b263a2325c0f66a5e5043be">lg::cuda::linear_sparse_forward</a></div><div class="ttdeci">void linear_sparse_forward(float *weights, float *bias, float *inputs, float *outputs, int *indices, int *indices_count, int input_size, int output_size)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_dropout_html_af45ddcc72851f4889d4bd361d82df748"><div class="ttname"><a href="classlg_1_1cudnn_1_1_dropout.html#af45ddcc72851f4889d4bd361d82df748">lg::cudnn::Dropout::forward</a></div><div class="ttdeci">void forward(void *input, void *output, void *reserve_space_buffer)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_pooling_html_a08072ec59a01232cef7531876f729f73"><div class="ttname"><a href="classlg_1_1cudnn_1_1_pooling.html#a08072ec59a01232cef7531876f729f73">lg::cudnn::Pooling::create</a></div><div class="ttdeci">void create(const int input_width, const int input_height, const int input_count, const int batch_size, const int pooling_width, const int pooling_height, const PoolingType type)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a965f4592cfb4e6b9f7f1abfa3a1005d8"><div class="ttname"><a href="namespacelg_1_1cuda.html#a965f4592cfb4e6b9f7f1abfa3a1005d8">lg::cuda::normalization_update_parameters</a></div><div class="ttdeci">void normalization_update_parameters(float *gamma, float *beta, float *d_gamma, float *d_beta, float momentum, int size, float learningrate)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00219">CPU_backend.cpp:219</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_aabc1ca86849f1b325416d5fc042d4cee"><div class="ttname"><a href="namespacelg_1_1cuda.html#aabc1ca86849f1b325416d5fc042d4cee">lg::cuda::convn_update_parameters</a></div><div class="ttdeci">void convn_update_parameters(float *weights, float *bias, float *weights_deltas, float *bias_deltas, int filter_area, int input_count, int filter_count, float learningrate)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00045">CPU_backend.cpp:45</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_af6f534536e457051e65effdbc7534a6d"><div class="ttname"><a href="namespacelg_1_1cuda.html#af6f534536e457051e65effdbc7534a6d">lg::cuda::softmax_forward</a></div><div class="ttdeci">void softmax_forward(float *inputs, float *outputs, float scale, int size, float epsilon)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00449">CPU_backend.cpp:449</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_dropout_html_ae8da161cb40aed9d4ba0509cfaed1352"><div class="ttname"><a href="classlg_1_1cudnn_1_1_dropout.html#ae8da161cb40aed9d4ba0509cfaed1352">lg::cudnn::Dropout::getReserveSpaceSize</a></div><div class="ttdeci">size_t getReserveSpaceSize(const int input_size)</div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ac49356b14c89bae0ff4d4c422719c48fad922f4546f4f7ac7e14a2885e756c219"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fad922f4546f4f7ac7e14a2885e756c219">lg::cudnn::ACTIVATION_SIGMOID</a></div><div class="ttdeci">@ ACTIVATION_SIGMOID</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00033">CUDA_backend.hpp:33</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_tensor_description_html_a3c28b8823548b85e3561b0259e923b1a"><div class="ttname"><a href="classlg_1_1cudnn_1_1_tensor_description.html#a3c28b8823548b85e3561b0259e923b1a">lg::cudnn::TensorDescription::get</a></div><div class="ttdeci">void * get()</div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ac49356b14c89bae0ff4d4c422719c48fac36699686abed0eb26a6fe942aed94aa"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fac36699686abed0eb26a6fe942aed94aa">lg::cudnn::ACTIVATION_ELU</a></div><div class="ttdeci">@ ACTIVATION_ELU</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00037">CUDA_backend.hpp:37</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a4b1138745ab9fde9daac0c42cb68f66f"><div class="ttname"><a href="namespacelg_1_1cuda.html#a4b1138745ab9fde9daac0c42cb68f66f">lg::cuda::sparse_indices</a></div><div class="ttdeci">void sparse_indices(float *inputs, int inputs_size, int *indices, int *tmp_indices, int *indices_count)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a2924760c84069a2841f300848c0d7b85"><div class="ttname"><a href="namespacelg_1_1cuda.html#a2924760c84069a2841f300848c0d7b85">lg::cuda::selu_forward</a></div><div class="ttdeci">void selu_forward(float *inputs, float *outputs, int size)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_activation_html"><div class="ttname"><a href="classlg_1_1cudnn_1_1_activation.html">lg::cudnn::Activation</a></div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00062">CUDA_backend.hpp:62</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a2dfc5b5558f9fc2dd45adae28f200594"><div class="ttname"><a href="namespacelg_1_1cuda.html#a2dfc5b5558f9fc2dd45adae28f200594">lg::cuda::image_scale</a></div><div class="ttdeci">void image_scale(float *image, float *result_buffer, const int width, const int height, const int channels, const float scale_factor)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_dropout_html_a27ce1a6ddce88949121934f3599b3552"><div class="ttname"><a href="classlg_1_1cudnn_1_1_dropout.html#a27ce1a6ddce88949121934f3599b3552">lg::cudnn::Dropout::create</a></div><div class="ttdeci">void create(const int input_size, const float dropout_probability, void *state_buffer)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a3a18f9046738e9209bbc4bdd101c2915"><div class="ttname"><a href="namespacelg_1_1cuda.html#a3a18f9046738e9209bbc4bdd101c2915">lg::cuda::averagepooling_backward</a></div><div class="ttdeci">void averagepooling_backward(float *out_errors, float *errors, int input_width, int input_height, int input_count, int stride, int filter_size, int output_width, int output_height)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00353">CPU_backend.cpp:353</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_pooling_html_abf652f83a4e4e570ee6e43b0913ca759"><div class="ttname"><a href="classlg_1_1cudnn_1_1_pooling.html#abf652f83a4e4e570ee6e43b0913ca759">lg::cudnn::Pooling::backward</a></div><div class="ttdeci">void backward(void *input, void *outputs, void *errors, void *out_errors)</div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_a450ec4165ca3788e681e05f42260afc6"><div class="ttname"><a href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6">lg::cudnn::PoolingType</a></div><div class="ttdeci">PoolingType</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00040">CUDA_backend.hpp:40</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_convolution_html"><div class="ttname"><a href="classlg_1_1cudnn_1_1_convolution.html">lg::cudnn::Convolution</a></div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00078">CUDA_backend.hpp:78</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a6155fb898132cd2eea9ab0bebf05da91"><div class="ttname"><a href="namespacelg_1_1cuda.html#a6155fb898132cd2eea9ab0bebf05da91">lg::cuda::image_add_noise</a></div><div class="ttdeci">void image_add_noise(float *image, const int width, const int height, const int channels, const float noise_probability)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_activation_html_aabd2da347135cfae195fe814648f6b4b"><div class="ttname"><a href="classlg_1_1cudnn_1_1_activation.html#aabd2da347135cfae195fe814648f6b4b">lg::cudnn::Activation::~Activation</a></div><div class="ttdeci">~Activation()</div></div>
<div class="ttc" id="anamespacelg_html"><div class="ttname"><a href="namespacelg.html">lg</a></div><div class="ttdoc">INCLUDES.</div><div class="ttdef"><b>Definition:</b> <a href="linear__regression_8cpp_source.html#l00017">linear_regression.cpp:17</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_ae6100dbc18d64618537e768e67a5eae4"><div class="ttname"><a href="namespacelg_1_1cuda.html#ae6100dbc18d64618537e768e67a5eae4">lg::cuda::softmax_backward</a></div><div class="ttdeci">void softmax_backward(float *errors, float *out_errors, float *outputs, int size)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00464">CPU_backend.cpp:464</a></div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_a450ec4165ca3788e681e05f42260afc6a59513495a6fbd432089720a7908c910e"><div class="ttname"><a href="namespacelg_1_1cudnn.html#a450ec4165ca3788e681e05f42260afc6a59513495a6fbd432089720a7908c910e">lg::cudnn::POOLING_MAX</a></div><div class="ttdeci">@ POOLING_MAX</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00042">CUDA_backend.hpp:42</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a87ec4c9b53aef96dbfefda3df54dfa2d"><div class="ttname"><a href="namespacelg_1_1cuda.html#a87ec4c9b53aef96dbfefda3df54dfa2d">lg::cuda::image_horizontal_flip</a></div><div class="ttdeci">void image_horizontal_flip(float *image, const int width, const int height, const int channels)</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_dropout_html_a42ee5e103620977da2950ada0ff1e2b6"><div class="ttname"><a href="classlg_1_1cudnn_1_1_dropout.html#a42ee5e103620977da2950ada0ff1e2b6">lg::cudnn::Dropout::~Dropout</a></div><div class="ttdeci">~Dropout()</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a4f1ff47b761603f6600eab5dcdfb0f43"><div class="ttname"><a href="namespacelg_1_1cuda.html#a4f1ff47b761603f6600eab5dcdfb0f43">lg::cuda::cost_crossentropy</a></div><div class="ttdeci">void cost_crossentropy(float *prediction, float *target, float *errors, int size)</div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_a2ca6eb7e6ef6c6530cf8ccd16d4bc780"><div class="ttname"><a href="namespacelg_1_1cudnn.html#a2ca6eb7e6ef6c6530cf8ccd16d4bc780">lg::cudnn::init</a></div><div class="ttdeci">int init()</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a8c62455098b6a8ab29a6113e840175a8"><div class="ttname"><a href="namespacelg_1_1cuda.html#a8c62455098b6a8ab29a6113e840175a8">lg::cuda::dropout_forward</a></div><div class="ttdeci">void dropout_forward(float *inputs, float *outputs, unsigned int seed, float dropout_probability, bool training, int size)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_ab502580e89328622329728926b168ced"><div class="ttname"><a href="namespacelg_1_1cuda.html#ab502580e89328622329728926b168ced">lg::cuda::maxpooling_backward</a></div><div class="ttdeci">void maxpooling_backward(float *out_errors, float *errors, int *maxbuffer, int input_width, int input_height, int input_count, int stride, int filter_size, int output_width, int output_height)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00298">CPU_backend.cpp:298</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a17f5d386c6a971e477fefb1c443fb408"><div class="ttname"><a href="namespacelg_1_1cuda.html#a17f5d386c6a971e477fefb1c443fb408">lg::cuda::linear_forward</a></div><div class="ttdeci">void linear_forward(float *weights, float *bias, float *inputs, float *outputs, int input_size, int output_size, bool use_bias, bool accumulate)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00066">CPU_backend.cpp:66</a></div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ac49356b14c89bae0ff4d4c422719c48fa49219e1ec5035b65f661fc89c955008c"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fa49219e1ec5035b65f661fc89c955008c">lg::cudnn::ACTIVATION_RELU</a></div><div class="ttdeci">@ ACTIVATION_RELU</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00034">CUDA_backend.hpp:34</a></div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ac49356b14c89bae0ff4d4c422719c48fa5a518d7d7ee3dc7cd313ff5a209d08f3"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ac49356b14c89bae0ff4d4c422719c48fa5a518d7d7ee3dc7cd313ff5a209d08f3">lg::cudnn::ACTIVATION_CLIPPED_RELU</a></div><div class="ttdeci">@ ACTIVATION_CLIPPED_RELU</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00036">CUDA_backend.hpp:36</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_convolution_html_a4ff6bc869cfb20fcd30321e346a46466"><div class="ttname"><a href="classlg_1_1cudnn_1_1_convolution.html#a4ff6bc869cfb20fcd30321e346a46466">lg::cudnn::Convolution::getWorkspaceSize</a></div><div class="ttdeci">int getWorkspaceSize()</div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_convolution_html_aa0224d51c8124d8d7c30e39fdcd2c35f"><div class="ttname"><a href="classlg_1_1cudnn_1_1_convolution.html#aa0224d51c8124d8d7c30e39fdcd2c35f">lg::cudnn::Convolution::~Convolution</a></div><div class="ttdeci">~Convolution()</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a06d4a9fec2e50a26d69a90897dbd7d84"><div class="ttname"><a href="namespacelg_1_1cuda.html#a06d4a9fec2e50a26d69a90897dbd7d84">lg::cuda::gradient_clipping</a></div><div class="ttdeci">void gradient_clipping(float *deltas, int size, const float clipping_deviation)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00490">CPU_backend.cpp:490</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a9faebc3673f09ecfc225c21738da5af3"><div class="ttname"><a href="namespacelg_1_1cuda.html#a9faebc3673f09ecfc225c21738da5af3">lg::cuda::maxpooling_forward</a></div><div class="ttdeci">void maxpooling_forward(float *inputs, float *outputs, int *maxbuffer, int input_width, int input_height, int input_count, int stride, int filter_size, int output_width, int output_height)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00250">CPU_backend.cpp:250</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_convolution_html_ad4f81402d0770c413f0d79027bf39644"><div class="ttname"><a href="classlg_1_1cudnn_1_1_convolution.html#ad4f81402d0770c413f0d79027bf39644">lg::cudnn::Convolution::accumulate_deltas</a></div><div class="ttdeci">void accumulate_deltas(void *input, void *output, void *errors, void *filter_deltas, void *bias_deltas, void *workspace)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_aa4ef754e9424188009a71c1a363aa94d"><div class="ttname"><a href="namespacelg_1_1cuda.html#aa4ef754e9424188009a71c1a363aa94d">lg::cuda::convn_backward</a></div><div class="ttdeci">void convn_backward(float *weights, float *out_errors, float *errors, int *in_weight_map, int *in_out_map, int input_count, int output_size, int input_width, int input_height, int filter_area, int filters_count)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00033">CPU_backend.cpp:33</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_convolution_html_a4b00db764114c64c6d2ddef7cfde6656"><div class="ttname"><a href="classlg_1_1cudnn_1_1_convolution.html#a4b00db764114c64c6d2ddef7cfde6656">lg::cudnn::Convolution::backward</a></div><div class="ttdeci">void backward(void *errors, void *output_errors, void *weights, void *workspace)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_ae6adb1a572de78eae4715c1c8137c026"><div class="ttname"><a href="namespacelg_1_1cuda.html#ae6adb1a572de78eae4715c1c8137c026">lg::cuda::relu_forward</a></div><div class="ttdeci">void relu_forward(float *inputs, float *outputs, int size)</div></div>
<div class="ttc" id="anamespacelg_1_1cudnn_html_ae723bd7649b468936d3f5ffb1163dd28ad269c23225751f5a6bc371f8ed8ceabd"><div class="ttname"><a href="namespacelg_1_1cudnn.html#ae723bd7649b468936d3f5ffb1163dd28ad269c23225751f5a6bc371f8ed8ceabd">lg::cudnn::DATA_INT32</a></div><div class="ttdeci">@ DATA_INT32</div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00028">CUDA_backend.hpp:28</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_dropout_html"><div class="ttname"><a href="classlg_1_1cudnn_1_1_dropout.html">lg::cudnn::Dropout</a></div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a__backend_8hpp_source.html#l00134">CUDA_backend.hpp:134</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_ae0db6f2ac2908e7161386f0a36df4560"><div class="ttname"><a href="namespacelg_1_1cuda.html#ae0db6f2ac2908e7161386f0a36df4560">lg::cuda::selu_backward</a></div><div class="ttdeci">void selu_backward(float *errors, float *out_errors, float *outputs, int size)</div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a2fa8129596126da6ab6fd12b7570e256"><div class="ttname"><a href="namespacelg_1_1cuda.html#a2fa8129596126da6ab6fd12b7570e256">lg::cuda::convn_accumulate_deltas</a></div><div class="ttdeci">void convn_accumulate_deltas(float *weights_deltas, float *bias_deltas, float *errors, float *inputs, float *outputs, int *out_in_map, int input_count, int input_width, int input_height, int output_size, int filter_area, int filters_count)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00039">CPU_backend.cpp:39</a></div></div>
<div class="ttc" id="anamespacelg_1_1cuda_html_a85299cc9e76e9ff15803eb9101e78460"><div class="ttname"><a href="namespacelg_1_1cuda.html#a85299cc9e76e9ff15803eb9101e78460">lg::cuda::normalization_forward</a></div><div class="ttdeci">void normalization_forward(float *inputs, float *deviation, float *normalized, float *outputs, float *variance, float *gamma, float *beta, float epsilon, int size)</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_u__backend_8cpp_source.html#l00165">CPU_backend.cpp:165</a></div></div>
<div class="ttc" id="aclasslg_1_1cudnn_1_1_pooling_html_a7ecd9addedd5778e0ecca3dedf7aa15c"><div class="ttname"><a href="classlg_1_1cudnn_1_1_pooling.html#a7ecd9addedd5778e0ecca3dedf7aa15c">lg::cudnn::Pooling::Pooling</a></div><div class="ttdeci">Pooling()</div></div>
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_7122151c7af8fde8aa600fecb43c8e35.html">lg</a></li><li class="navelem"><a class="el" href="dir_b5d6630a36a5437c9ee223913104b574.html">src</a></li><li class="navelem"><a class="el" href="dir_5c48c5be69cc0615361a2f3b9f160d6f.html">deep_learning</a></li><li class="navelem"><a class="el" href="_c_u_d_a__backend_8hpp.html">CUDA_backend.hpp</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
