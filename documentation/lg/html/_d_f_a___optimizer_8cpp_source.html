<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>On the applicability of the Hadamard as an input modulator for problems of classification.: lg/src/deep_learning/DFA_Optimizer.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="cyz.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">On the applicability of the Hadamard as an input modulator for problems of classification.
   &#160;<span id="projectnumber">v2.2</span>
   </div>
   <div id="projectbrief">Documentation for lg.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('_d_f_a___optimizer_8cpp_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">DFA_Optimizer.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="_d_f_a___optimizer_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">// Original Source Code by Meroni (https://www.github.com/Flowx08/).</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">// Modified by Curt√≥ &amp; Zarza.</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">// c@decurto.tw z@dezarza.tw</span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160; </div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="_d_f_a___optimizer_8hpp.html">DFA_Optimizer.hpp</a>&quot;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="_neural___network_8hpp.html">Neural_Network.hpp</a>&quot;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;../util/ensure.hpp&quot;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160; </div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacelg.html">lg</a></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;{</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;    </div>
<div class="line"><a name="l00019"></a><span class="lineno"><a class="line" href="classlg_1_1_d_f_a___optimizer.html#a05ad553f5266eec5f1ebc7f4af499e59">   19</a></span>&#160;    <a class="code" href="classlg_1_1_d_f_a___optimizer.html#a05ad553f5266eec5f1ebc7f4af499e59">DFA_Optimizer::DFA_Optimizer</a>()</div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;    {</div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;        _current_sample = 0;</div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;        <a class="code" href="classlg_1_1_optimizer.html#ab4b4614774d90384ce737c34d2f7e707">_learningrate</a> = 0.1;</div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;        <a class="code" href="classlg_1_1_optimizer.html#abc79def36e87cb1402dadfa725995a99">_momentum</a> = 0;</div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;        _batch_size = 1;</div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;        <a class="code" href="classlg_1_1_optimizer.html#ad9510214ac5b117e7dd979b16ce5f4ad">_costfunction</a> = <a class="code" href="classlg_1_1_cost.html#acced4bdd5fe2608b09fd054071e66a76ad913a43ba24d17f8651aae283768dc1b">Cost::SquaredError</a>;</div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;    }</div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;    </div>
<div class="line"><a name="l00029"></a><span class="lineno"><a class="line" href="classlg_1_1_d_f_a___optimizer.html#a43840a6f93e7cfb6389d31b3c25488f9">   29</a></span>&#160;    <a class="code" href="classlg_1_1_d_f_a___optimizer.html#a05ad553f5266eec5f1ebc7f4af499e59">DFA_Optimizer::DFA_Optimizer</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> batch_size, <span class="keyword">const</span> <span class="keywordtype">double</span> learningrate, <span class="keyword">const</span> <span class="keywordtype">double</span> momentum,</div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;                    <span class="keyword">const</span> <a class="code" href="classlg_1_1_cost.html#acced4bdd5fe2608b09fd054071e66a76">Cost::CostType</a> cost_function)</div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;    {</div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;        _current_sample = 0;</div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;        <a class="code" href="classlg_1_1_optimizer.html#ab4b4614774d90384ce737c34d2f7e707">_learningrate</a> = learningrate;</div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;        <a class="code" href="classlg_1_1_optimizer.html#abc79def36e87cb1402dadfa725995a99">_momentum</a> = momentum;</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;        _batch_size = batch_size;</div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;        <a class="code" href="classlg_1_1_optimizer.html#ad9510214ac5b117e7dd979b16ce5f4ad">_costfunction</a> = cost_function;</div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;        _feedback_weights.<a class="code" href="classlg_1_1_tensor.html#a87004750092303da63bc71cc4086f459">setshape</a>(200 * 10);</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;        _feedback_weights.<a class="code" href="classlg_1_1_tensor.html#a9435567e5204d9edc2a74294f927d265">fill</a>(0, 0.5);</div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; _feedback_weights.<a class="code" href="classlg_1_1_tensor.html#a2037c387b1f91c91e604b16b4ade3177">size</a>(); c++) {</div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;            <span class="comment">//if (rand() % 1000 &lt; 700) _feedback_weights[c] = 0;</span></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;            <span class="comment">//if (_feedback_weights[c] &lt; 0) _feedback_weights[c] = -1;</span></div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;            <span class="comment">//else _feedback_weights[c] = 1; </span></div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;        }</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;        _feedback_errors.<a class="code" href="classlg_1_1_tensor.html#a87004750092303da63bc71cc4086f459">setshape</a>(200);</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;        _feedback_errors.<a class="code" href="classlg_1_1_tensor.html#a9435567e5204d9edc2a74294f927d265">fill</a>(0);</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;    }</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;    </div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="preprocessor">    #ifdef CUDA_BACKEND</span></div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160; </div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classlg_1_1_d_f_a___optimizer.html#abb7a6bac552681ba5dbeb5c66db7b487">DFA_Optimizer::fit</a>(<a class="code" href="classlg_1_1_neural___network.html">Neural_Network</a>&amp; net, <a class="code" href="classlg_1_1_c_u_d_a___tensor.html">CUDA_Tensor_float</a> &amp;inputs, <a class="code" href="classlg_1_1_c_u_d_a___tensor.html">CUDA_Tensor_float</a> &amp;targets)</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    {</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;        <span class="comment">/*</span></div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<span class="comment">        ensure(targets.depth() == 1 &amp;&amp; targets.height() == 1);</span></div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="comment">        </span></div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;<span class="comment">        //Feedforward</span></div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="comment">        net.run(inputs, true);</span></div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="comment">        </span></div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="comment">        //Shortcut</span></div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="comment">        std::vector&lt; Node_Network &gt; &amp;nodes = net.getNodes();</span></div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="comment">        //Reset errors</span></div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment">        for (int c = 0; c &lt; (int)nodes.size(); c++)</span></div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment">            nodes[c].reset_errors();</span></div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment">        </span></div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="comment">        //Calculate cost on GPU</span></div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;<span class="comment">        _costfunction.getDeltacuda(nodes.back().getOperation()-&gt;_outputs, targets, nodes.back().getOperation()-&gt;_errors);</span></div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="comment">        _error = _costfunction.getErrorcuda(nodes.back().getOperation()-&gt;_outputs, targets);</span></div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;<span class="comment">        //Accumulate deltas</span></div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;<span class="comment">        for (int c = (int)nodes.size()-1; c &gt;= 0; c--) {</span></div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="comment">            nodes[c].backprop();</span></div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="comment">            nodes[c].accumulate_deltas();</span></div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="comment">        }</span></div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;<span class="comment">        </span></div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="comment">        //Update weights if we reach the batch size</span></div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="comment">        if (++_current_sample &gt;= _batch_size) {</span></div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="comment">            </span></div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="comment">            //Update weights and reset deltas</span></div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;<span class="comment">            for (int c = 0; c &lt; (int)nodes.size(); c++) {</span></div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="comment">                nodes[c].update_parameters(_learningrate);</span></div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="comment">                nodes[c].reset_deltas(_momentum);</span></div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="comment">            }</span></div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="comment">            _current_sample = 0;</span></div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="comment">        }</span></div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment">        */</span></div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;    }</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;    </div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;<span class="preprocessor">    #else</span></div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160; </div>
<div class="line"><a name="l00093"></a><span class="lineno"><a class="line" href="classlg_1_1_d_f_a___optimizer.html#abb7a6bac552681ba5dbeb5c66db7b487">   93</a></span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classlg_1_1_d_f_a___optimizer.html#abb7a6bac552681ba5dbeb5c66db7b487">DFA_Optimizer::fit</a>(<a class="code" href="classlg_1_1_neural___network.html">Neural_Network</a>&amp; net, <a class="code" href="classlg_1_1_tensor.html">Tensor_float</a> &amp;inputs, <a class="code" href="classlg_1_1_tensor.html">Tensor_float</a> &amp;targets)</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    {</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;        <a class="code" href="ensure_8hpp.html#a1e46c9385e2ecb3c83bbac805a1e2bdf">ensure</a>(targets.<a class="code" href="classlg_1_1_tensor.html#a4c62f84db9978b1cb0a38b23af493a88">depth</a>() == 1 &amp;&amp; targets.<a class="code" href="classlg_1_1_tensor.html#a3d4bd6ecfb08ce24f37b32b07f5b16ea">height</a>() == 1);</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;        </div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;        <span class="comment">//Feedforward</span></div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;        net.<a class="code" href="classlg_1_1_neural___network.html#a0ae2ea9aae70d837ea6648afd2043fb0">run</a>(inputs, <span class="keyword">true</span>);</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;            </div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;        <span class="comment">//Shortcuts</span></div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;        std::vector&lt; Node_Network &gt;&amp; nodes = net.<a class="code" href="classlg_1_1_neural___network.html#a1a454e036a595bf75373e8f1514908ae">getNodes</a>();</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160; </div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        <span class="comment">//Reset errors</span></div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; (int)nodes.size(); c++)</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;            nodes[c].reset_errors();</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;        </div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;        <span class="comment">//Calculate cost on host</span></div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;        <a class="code" href="classlg_1_1_optimizer.html#ad9510214ac5b117e7dd979b16ce5f4ad">_costfunction</a>.<a class="code" href="classlg_1_1_cost.html#a257ad161b425645f97fb5eb5751e6ea5">getDelta</a>(nodes.back().getOperation()-&gt;_outputs, targets, nodes.back().getOperation()-&gt;_errors);</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;        <a class="code" href="classlg_1_1_optimizer.html#af3fca6b57fd6c4b2e8dfd2cd29f3baa1">_error</a> = <a class="code" href="classlg_1_1_optimizer.html#ad9510214ac5b117e7dd979b16ce5f4ad">_costfunction</a>.<a class="code" href="classlg_1_1_cost.html#a12ca6b5b6131831246fc2844113c78bc">getError</a>(nodes.back().getOperation()-&gt;_outputs, targets);</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;        </div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;        <span class="keyword">const</span> <a class="code" href="classlg_1_1_tensor.html">Tensor_float</a>&amp; errs = nodes.back().getOperation()-&gt;_errors;</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;                </div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;        <span class="keyword">const</span> <span class="keywordtype">float</span> scale = 0.09;</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;        <span class="keywordtype">int</span> l = 0;</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = 0; k &lt; _feedback_errors.<a class="code" href="classlg_1_1_tensor.html#a2037c387b1f91c91e604b16b4ade3177">size</a>(); k++) {</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;            _feedback_errors[k] = 0;</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> z = 0; z &lt; errs.<a class="code" href="classlg_1_1_tensor.html#a2037c387b1f91c91e604b16b4ade3177">size</a>(); z++) {</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;                _feedback_errors[k] += errs[z] * _feedback_weights[l++] * scale;</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;            }</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;        }</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;        </div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;        nodes.back().backprop();</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160; </div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;        <span class="comment">//Accumulate deltas</span></div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;        l = 0;</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = (<span class="keywordtype">int</span>)nodes.size()-1; c &gt;= 0 ; c--) {</div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;            <a class="code" href="classlg_1_1_operation.html">Operation</a>* op = nodes[c].getOperation();</div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;            <span class="keywordflow">if</span> (op-&gt;<a class="code" href="classlg_1_1_operation.html#ab8e6bfb008563515b664e0563409a6a8">get_type</a>() == <a class="code" href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aaf89a95018af553c2dc9a3dd979d27c8b">Operation::Softmax</a> ||</div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;                op-&gt;<a class="code" href="classlg_1_1_operation.html#ab8e6bfb008563515b664e0563409a6a8">get_type</a>() == <a class="code" href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aa0c92589e337a4a18dfa4fdd11574c5c9">Operation::Sigmoid</a> ||</div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;                op-&gt;<a class="code" href="classlg_1_1_operation.html#ab8e6bfb008563515b664e0563409a6a8">get_type</a>() == <a class="code" href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aa87e93ea55883c410fc82257892ea78ed">Operation::Relu</a> ||</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;                op-&gt;<a class="code" href="classlg_1_1_operation.html#ab8e6bfb008563515b664e0563409a6a8">get_type</a>() == <a class="code" href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aafdc34df812bca58e27d52c91cf58d493">Operation::Tanh</a> ||</div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;                op-&gt;<a class="code" href="classlg_1_1_operation.html#ab8e6bfb008563515b664e0563409a6a8">get_type</a>() == <a class="code" href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aae09824724b224b544c0d9bb748d32f30">Operation::Averagepooling</a> ||</div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;                op-&gt;<a class="code" href="classlg_1_1_operation.html#ab8e6bfb008563515b664e0563409a6a8">get_type</a>() == <a class="code" href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aa2a84b38d9c64d804783a03e1ec2622e3">Operation::Maxpooling</a>)</div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;            {</div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160; </div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;                <a class="code" href="classlg_1_1_tensor.html">Tensor_float</a>&amp; node_errors = nodes[c].getOperation()-&gt;_errors;</div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = 0; k &lt; node_errors.<a class="code" href="classlg_1_1_tensor.html#a2037c387b1f91c91e604b16b4ade3177">size</a>(); k++) {</div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;                    node_errors[k] += _feedback_errors[l++];</div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;                    <span class="keywordflow">if</span> (l &gt;= _feedback_errors.<a class="code" href="classlg_1_1_tensor.html#a2037c387b1f91c91e604b16b4ade3177">size</a>()) l = 0;</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;                }</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160; </div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;                nodes[c].backprop();</div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;            }</div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;            <span class="keywordflow">else</span> <span class="keywordflow">if</span> (op-&gt;<a class="code" href="classlg_1_1_operation.html#ab8e6bfb008563515b664e0563409a6a8">get_type</a>() == <a class="code" href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aa6ced42370219cffa18db29b4b1d035a5">Operation::Normalization</a>)</div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;            {</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;                nodes[c].backprop();</div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;            }</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160; </div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;            <span class="comment">//Calculate deltas</span></div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;            nodes[c].accumulate_deltas();</div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;        }</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;        </div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;        <span class="comment">/*</span></div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;<span class="comment">        nodes.back().backprop();</span></div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;<span class="comment">        //Accumulate deltas</span></div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="comment">        int l = 1;</span></div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="comment">        for (int c = (int)nodes.size()-1; c &gt;= 0 ; c--) {</span></div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="comment">            Operation* op = nodes[c].getOperation();</span></div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="comment">            if (op-&gt;get_type() == Operation::Softmax ||</span></div>
<div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;<span class="comment">                op-&gt;get_type() == Operation::Sigmoid ||</span></div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;<span class="comment">                op-&gt;get_type() == Operation::Relu ||</span></div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;<span class="comment">                op-&gt;get_type() == Operation::Tanh ||</span></div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;<span class="comment">                op-&gt;get_type() == Operation::Averagepooling ||</span></div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="comment">                op-&gt;get_type() == Operation::Maxpooling)</span></div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="comment">            {</span></div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="comment">                for (int z = 0; z &lt; errs.size(); z++) {</span></div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;<span class="comment">                    Tensor_float&amp; node_errors = nodes[c].getOperation()-&gt;_errors;</span></div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;<span class="comment">                    float scale = 0.01;</span></div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;<span class="comment">                    for (int k = 0; k &lt; node_errors.size(); k++) {</span></div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;<span class="comment">                        node_errors[k] += errs[z] * _feedback_weights[l++] * scale;</span></div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;<span class="comment">                        if (l &gt;= _feedback_weights.size()) l = 0;</span></div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;<span class="comment">                    }</span></div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;<span class="comment">                }</span></div>
<div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;<span class="comment">                nodes[c].backprop();</span></div>
<div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="comment">            }</span></div>
<div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;<span class="comment">            else if (op-&gt;get_type() == Operation::Normalization)</span></div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;<span class="comment">            {</span></div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;<span class="comment">                nodes[c].backprop();</span></div>
<div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;<span class="comment">            }</span></div>
<div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;<span class="comment">            //Calculate deltas</span></div>
<div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;<span class="comment">            nodes[c].accumulate_deltas();</span></div>
<div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;<span class="comment">        }</span></div>
<div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;<span class="comment">        */</span></div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;        </div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;        <span class="comment">//Update weights if we reach the batch size</span></div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;        <span class="keywordflow">if</span> (++_current_sample &gt;= _batch_size) {</div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;            </div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;            <span class="comment">//Update weights and reset deltas</span></div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; (int)nodes.size(); c++) {</div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;                nodes[c].update_parameters(<a class="code" href="classlg_1_1_optimizer.html#ab4b4614774d90384ce737c34d2f7e707">_learningrate</a>);</div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;                nodes[c].reset_deltas(<a class="code" href="classlg_1_1_optimizer.html#abc79def36e87cb1402dadfa725995a99">_momentum</a>);</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;            }</div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160; </div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;            _current_sample = 0;</div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;        }</div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;    }</div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160; </div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="preprocessor">    #endif</span></div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160; </div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;} <span class="comment">/* namespace lg */</span></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<div class="ttc" id="aclasslg_1_1_optimizer_html_ab4b4614774d90384ce737c34d2f7e707"><div class="ttname"><a href="classlg_1_1_optimizer.html#ab4b4614774d90384ce737c34d2f7e707">lg::Optimizer::_learningrate</a></div><div class="ttdeci">float _learningrate</div><div class="ttdef"><b>Definition:</b> <a href="_optimizer_8hpp_source.html#l00039">Optimizer.hpp:39</a></div></div>
<div class="ttc" id="aclasslg_1_1_operation_html_a204bb2a8c1903febe08ea909f1684f4aafdc34df812bca58e27d52c91cf58d493"><div class="ttname"><a href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aafdc34df812bca58e27d52c91cf58d493">lg::Operation::Tanh</a></div><div class="ttdeci">@ Tanh</div><div class="ttdef"><b>Definition:</b> <a href="_operation_8hpp_source.html#l00042">Operation.hpp:42</a></div></div>
<div class="ttc" id="aclasslg_1_1_operation_html_a204bb2a8c1903febe08ea909f1684f4aa2a84b38d9c64d804783a03e1ec2622e3"><div class="ttname"><a href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aa2a84b38d9c64d804783a03e1ec2622e3">lg::Operation::Maxpooling</a></div><div class="ttdeci">@ Maxpooling</div><div class="ttdef"><b>Definition:</b> <a href="_operation_8hpp_source.html#l00052">Operation.hpp:52</a></div></div>
<div class="ttc" id="aclasslg_1_1_cost_html_a12ca6b5b6131831246fc2844113c78bc"><div class="ttname"><a href="classlg_1_1_cost.html#a12ca6b5b6131831246fc2844113c78bc">lg::Cost::getError</a></div><div class="ttdeci">float getError(Tensor_float &amp;prediction, Tensor_float &amp;target)</div><div class="ttdoc">Calculate errors.</div><div class="ttdef"><b>Definition:</b> <a href="_cost_8cpp_source.html#l00066">Cost.cpp:66</a></div></div>
<div class="ttc" id="aclasslg_1_1_d_f_a___optimizer_html_abb7a6bac552681ba5dbeb5c66db7b487"><div class="ttname"><a href="classlg_1_1_d_f_a___optimizer.html#abb7a6bac552681ba5dbeb5c66db7b487">lg::DFA_Optimizer::fit</a></div><div class="ttdeci">void fit(Neural_Network &amp;net, Tensor_float &amp;inputs, Tensor_float &amp;targets)</div><div class="ttdef"><b>Definition:</b> <a href="_d_f_a___optimizer_8cpp_source.html#l00093">DFA_Optimizer.cpp:93</a></div></div>
<div class="ttc" id="aclasslg_1_1_tensor_html"><div class="ttname"><a href="classlg_1_1_tensor.html">lg::Tensor&lt; float &gt;</a></div></div>
<div class="ttc" id="aensure_8hpp_html_a1e46c9385e2ecb3c83bbac805a1e2bdf"><div class="ttname"><a href="ensure_8hpp.html#a1e46c9385e2ecb3c83bbac805a1e2bdf">ensure</a></div><div class="ttdeci">#define ensure(x)</div><div class="ttdef"><b>Definition:</b> <a href="ensure_8hpp_source.html#l00017">ensure.hpp:17</a></div></div>
<div class="ttc" id="aclasslg_1_1_tensor_html_a2037c387b1f91c91e604b16b4ade3177"><div class="ttname"><a href="classlg_1_1_tensor.html#a2037c387b1f91c91e604b16b4ade3177">lg::Tensor::size</a></div><div class="ttdeci">const int size() const</div><div class="ttdef"><b>Definition:</b> <a href="_tensor_8hpp_source.html#l00063">Tensor.hpp:63</a></div></div>
<div class="ttc" id="aclasslg_1_1_operation_html"><div class="ttname"><a href="classlg_1_1_operation.html">lg::Operation</a></div><div class="ttdef"><b>Definition:</b> <a href="_operation_8hpp_source.html#l00028">Operation.hpp:28</a></div></div>
<div class="ttc" id="aclasslg_1_1_operation_html_a204bb2a8c1903febe08ea909f1684f4aa87e93ea55883c410fc82257892ea78ed"><div class="ttname"><a href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aa87e93ea55883c410fc82257892ea78ed">lg::Operation::Relu</a></div><div class="ttdeci">@ Relu</div><div class="ttdef"><b>Definition:</b> <a href="_operation_8hpp_source.html#l00043">Operation.hpp:43</a></div></div>
<div class="ttc" id="aclasslg_1_1_cost_html_a257ad161b425645f97fb5eb5751e6ea5"><div class="ttname"><a href="classlg_1_1_cost.html#a257ad161b425645f97fb5eb5751e6ea5">lg::Cost::getDelta</a></div><div class="ttdeci">void getDelta(Tensor_float &amp;prediction, Tensor_float &amp;target, Tensor_float &amp;errors)</div><div class="ttdoc">Calculate deltas.</div><div class="ttdef"><b>Definition:</b> <a href="_cost_8cpp_source.html#l00087">Cost.cpp:87</a></div></div>
<div class="ttc" id="aclasslg_1_1_tensor_html_a9435567e5204d9edc2a74294f927d265"><div class="ttname"><a href="classlg_1_1_tensor.html#a9435567e5204d9edc2a74294f927d265">lg::Tensor::fill</a></div><div class="ttdeci">void fill(const T val)</div><div class="ttdef"><b>Definition:</b> <a href="_tensor_8cpp_source.html#l00232">Tensor.cpp:232</a></div></div>
<div class="ttc" id="aclasslg_1_1_tensor_html_a3d4bd6ecfb08ce24f37b32b07f5b16ea"><div class="ttname"><a href="classlg_1_1_tensor.html#a3d4bd6ecfb08ce24f37b32b07f5b16ea">lg::Tensor::height</a></div><div class="ttdeci">const int height() const</div><div class="ttdef"><b>Definition:</b> <a href="_tensor_8hpp_source.html#l00065">Tensor.hpp:65</a></div></div>
<div class="ttc" id="aclasslg_1_1_operation_html_a204bb2a8c1903febe08ea909f1684f4aa6ced42370219cffa18db29b4b1d035a5"><div class="ttname"><a href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aa6ced42370219cffa18db29b4b1d035a5">lg::Operation::Normalization</a></div><div class="ttdeci">@ Normalization</div><div class="ttdef"><b>Definition:</b> <a href="_operation_8hpp_source.html#l00049">Operation.hpp:49</a></div></div>
<div class="ttc" id="aclasslg_1_1_neural___network_html_a0ae2ea9aae70d837ea6648afd2043fb0"><div class="ttname"><a href="classlg_1_1_neural___network.html#a0ae2ea9aae70d837ea6648afd2043fb0">lg::Neural_Network::run</a></div><div class="ttdeci">void run(Tensor_float input, const bool training=false)</div><div class="ttdef"><b>Definition:</b> <a href="_neural___network_8cpp_source.html#l00165">Neural_Network.cpp:165</a></div></div>
<div class="ttc" id="aclasslg_1_1_operation_html_ab8e6bfb008563515b664e0563409a6a8"><div class="ttname"><a href="classlg_1_1_operation.html#ab8e6bfb008563515b664e0563409a6a8">lg::Operation::get_type</a></div><div class="ttdeci">virtual const Type get_type() const</div><div class="ttdef"><b>Definition:</b> <a href="_operation_8cpp_source.html#l00085">Operation.cpp:85</a></div></div>
<div class="ttc" id="aclasslg_1_1_tensor_html_a4c62f84db9978b1cb0a38b23af493a88"><div class="ttname"><a href="classlg_1_1_tensor.html#a4c62f84db9978b1cb0a38b23af493a88">lg::Tensor::depth</a></div><div class="ttdeci">const int depth() const</div><div class="ttdef"><b>Definition:</b> <a href="_tensor_8hpp_source.html#l00066">Tensor.hpp:66</a></div></div>
<div class="ttc" id="aclasslg_1_1_neural___network_html"><div class="ttname"><a href="classlg_1_1_neural___network.html">lg::Neural_Network</a></div><div class="ttdef"><b>Definition:</b> <a href="_neural___network_8hpp_source.html#l00025">Neural_Network.hpp:25</a></div></div>
<div class="ttc" id="aclasslg_1_1_d_f_a___optimizer_html_a05ad553f5266eec5f1ebc7f4af499e59"><div class="ttname"><a href="classlg_1_1_d_f_a___optimizer.html#a05ad553f5266eec5f1ebc7f4af499e59">lg::DFA_Optimizer::DFA_Optimizer</a></div><div class="ttdeci">DFA_Optimizer()</div><div class="ttdef"><b>Definition:</b> <a href="_d_f_a___optimizer_8cpp_source.html#l00019">DFA_Optimizer.cpp:19</a></div></div>
<div class="ttc" id="aclasslg_1_1_cost_html_acced4bdd5fe2608b09fd054071e66a76ad913a43ba24d17f8651aae283768dc1b"><div class="ttname"><a href="classlg_1_1_cost.html#acced4bdd5fe2608b09fd054071e66a76ad913a43ba24d17f8651aae283768dc1b">lg::Cost::SquaredError</a></div><div class="ttdeci">@ SquaredError</div><div class="ttdef"><b>Definition:</b> <a href="_cost_8hpp_source.html#l00035">Cost.hpp:35</a></div></div>
<div class="ttc" id="a_d_f_a___optimizer_8hpp_html"><div class="ttname"><a href="_d_f_a___optimizer_8hpp.html">DFA_Optimizer.hpp</a></div></div>
<div class="ttc" id="aclasslg_1_1_cost_html_acced4bdd5fe2608b09fd054071e66a76"><div class="ttname"><a href="classlg_1_1_cost.html#acced4bdd5fe2608b09fd054071e66a76">lg::Cost::CostType</a></div><div class="ttdeci">CostType</div><div class="ttdef"><b>Definition:</b> <a href="_cost_8hpp_source.html#l00033">Cost.hpp:33</a></div></div>
<div class="ttc" id="aclasslg_1_1_neural___network_html_a1a454e036a595bf75373e8f1514908ae"><div class="ttname"><a href="classlg_1_1_neural___network.html#a1a454e036a595bf75373e8f1514908ae">lg::Neural_Network::getNodes</a></div><div class="ttdeci">std::vector&lt; Node_Network &gt; &amp; getNodes()</div><div class="ttdef"><b>Definition:</b> <a href="_neural___network_8cpp_source.html#l00200">Neural_Network.cpp:200</a></div></div>
<div class="ttc" id="aclasslg_1_1_operation_html_a204bb2a8c1903febe08ea909f1684f4aaf89a95018af553c2dc9a3dd979d27c8b"><div class="ttname"><a href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aaf89a95018af553c2dc9a3dd979d27c8b">lg::Operation::Softmax</a></div><div class="ttdeci">@ Softmax</div><div class="ttdef"><b>Definition:</b> <a href="_operation_8hpp_source.html#l00044">Operation.hpp:44</a></div></div>
<div class="ttc" id="aclasslg_1_1_optimizer_html_af3fca6b57fd6c4b2e8dfd2cd29f3baa1"><div class="ttname"><a href="classlg_1_1_optimizer.html#af3fca6b57fd6c4b2e8dfd2cd29f3baa1">lg::Optimizer::_error</a></div><div class="ttdeci">float _error</div><div class="ttdef"><b>Definition:</b> <a href="_optimizer_8hpp_source.html#l00041">Optimizer.hpp:41</a></div></div>
<div class="ttc" id="aclasslg_1_1_operation_html_a204bb2a8c1903febe08ea909f1684f4aa0c92589e337a4a18dfa4fdd11574c5c9"><div class="ttname"><a href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aa0c92589e337a4a18dfa4fdd11574c5c9">lg::Operation::Sigmoid</a></div><div class="ttdeci">@ Sigmoid</div><div class="ttdef"><b>Definition:</b> <a href="_operation_8hpp_source.html#l00041">Operation.hpp:41</a></div></div>
<div class="ttc" id="aclasslg_1_1_tensor_html_a87004750092303da63bc71cc4086f459"><div class="ttname"><a href="classlg_1_1_tensor.html#a87004750092303da63bc71cc4086f459">lg::Tensor::setshape</a></div><div class="ttdeci">void setshape(const int width)</div><div class="ttdef"><b>Definition:</b> <a href="_tensor_8cpp_source.html#l00065">Tensor.cpp:65</a></div></div>
<div class="ttc" id="anamespacelg_html"><div class="ttname"><a href="namespacelg.html">lg</a></div><div class="ttdoc">INCLUDES.</div><div class="ttdef"><b>Definition:</b> <a href="linear__regression_8cpp_source.html#l00017">linear_regression.cpp:17</a></div></div>
<div class="ttc" id="aclasslg_1_1_c_u_d_a___tensor_html"><div class="ttname"><a href="classlg_1_1_c_u_d_a___tensor.html">lg::CUDA_Tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="_c_u_d_a___tensor_8hpp_source.html#l00020">CUDA_Tensor.hpp:20</a></div></div>
<div class="ttc" id="aclasslg_1_1_operation_html_a204bb2a8c1903febe08ea909f1684f4aae09824724b224b544c0d9bb748d32f30"><div class="ttname"><a href="classlg_1_1_operation.html#a204bb2a8c1903febe08ea909f1684f4aae09824724b224b544c0d9bb748d32f30">lg::Operation::Averagepooling</a></div><div class="ttdeci">@ Averagepooling</div><div class="ttdef"><b>Definition:</b> <a href="_operation_8hpp_source.html#l00053">Operation.hpp:53</a></div></div>
<div class="ttc" id="a_neural___network_8hpp_html"><div class="ttname"><a href="_neural___network_8hpp.html">Neural_Network.hpp</a></div></div>
<div class="ttc" id="aclasslg_1_1_optimizer_html_abc79def36e87cb1402dadfa725995a99"><div class="ttname"><a href="classlg_1_1_optimizer.html#abc79def36e87cb1402dadfa725995a99">lg::Optimizer::_momentum</a></div><div class="ttdeci">float _momentum</div><div class="ttdef"><b>Definition:</b> <a href="_optimizer_8hpp_source.html#l00040">Optimizer.hpp:40</a></div></div>
<div class="ttc" id="aclasslg_1_1_optimizer_html_ad9510214ac5b117e7dd979b16ce5f4ad"><div class="ttname"><a href="classlg_1_1_optimizer.html#ad9510214ac5b117e7dd979b16ce5f4ad">lg::Optimizer::_costfunction</a></div><div class="ttdeci">Cost _costfunction</div><div class="ttdef"><b>Definition:</b> <a href="_optimizer_8hpp_source.html#l00042">Optimizer.hpp:42</a></div></div>
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_7122151c7af8fde8aa600fecb43c8e35.html">lg</a></li><li class="navelem"><a class="el" href="dir_b5d6630a36a5437c9ee223913104b574.html">src</a></li><li class="navelem"><a class="el" href="dir_5c48c5be69cc0615361a2f3b9f160d6f.html">deep_learning</a></li><li class="navelem"><a class="el" href="_d_f_a___optimizer_8cpp.html">DFA_Optimizer.cpp</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
